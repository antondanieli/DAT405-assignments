{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment4_complete.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sTsDfIVKsmL"
      },
      "source": [
        "# DAT405 Introduction to Data Science and AI \n",
        "## Assignment 4: Spam classification using Naïve Bayes \n",
        "\n",
        "The exercise takes place in a notebook environment where you can chose to use Jupyter or Google Colabs. We recommend you use Google Colabs as it will facilitate remote group-work and makes the assignment less technical. \n",
        "Hints:\n",
        "You can execute certain linux shell commands by prefixing the command with `!`. You can insert Markdown cells and code cells. The first you can use for documenting and explaining your results the second you can use writing code snippets that execute the tasks required.  \n",
        "\n",
        "In this assignment you will implement a Naïve Bayes classifier in Python that will classify emails into spam and non-spam (“ham”) classes.  Your program should be able to train on a given set of spam and “ham” datasets. \n",
        "You will work with the datasets available at https://spamassassin.apache.org/old/publiccorpus/. There are three types of files in this location: \n",
        "-\teasy-ham: non-spam messages typically quite easy to differentiate from spam messages. \n",
        "-\thard-ham: non-spam messages more difficult to differentiate \n",
        "-\tspam: spam messages \n",
        "\n",
        "**Execute the cell below to download and extract the data into the environment of the notebook -- it will take a few seconds.** If you chose to use Jupyter notebooks you will have to run the commands in the cell below on your local computer, with Windows you can use 7zip (https://www.7-zip.org/download.html) to decompress the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa37fBwRF-xe"
      },
      "source": [
        "#Download and extract data\n",
        "!wget https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2\n",
        "!wget https://spamassassin.apache.org/old/publiccorpus/20021010_hard_ham.tar.bz2\n",
        "!wget https://spamassassin.apache.org/old/publiccorpus/20021010_spam.tar.bz2\n",
        "!tar -xjf 20021010_easy_ham.tar.bz2\n",
        "!tar -xjf 20021010_hard_ham.tar.bz2\n",
        "!tar -xjf 20021010_spam.tar.bz2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdH1XTepLjZ3"
      },
      "source": [
        "*The* data is now in the three folders `easy_ham`, `hard_ham`, and `spam`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A53Gw00fBLG2"
      },
      "source": [
        "!ls -lah"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haN2Wdr5AXeO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGlWPVnSNzT7"
      },
      "source": [
        "###1. Preprocessing: \n",
        "1.\tNote that the email files contain a lot of extra information, besides the actual message. Ignore that and run on the entire text. \n",
        "2.\tWe don’t want to train and test on the same data. Split the spam and the ham datasets in a training set and a test set. (`hamtrain`, `spamtrain`, `hamtest`, and `spamtest`) **0.5p**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLj48CXC583G"
      },
      "source": [
        "## Rasmus Durgé, Anton Danielli\r\n",
        "### Time spent : 30 hours , 30 hours"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70KcwRue3N-Z"
      },
      "source": [
        "First off we read all the files, we didnt do any data cleaning since we at first needed all the text in the data to decide whether they were ham or spam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2sllUWXKblD"
      },
      "source": [
        "#pre-processing code \r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "\r\n",
        "#Function to read files\r\n",
        "def file_reader(folder):\r\n",
        "  data = os.listdir(os.path.abspath(folder))\r\n",
        "  data_list = []\r\n",
        "  for data in data_list:\r\n",
        "    data_list.append(open(folder + data, \"r\", errors='ignore').read())\r\n",
        "  return data_list\r\n",
        "\r\n",
        "#Separate files into easy, hard and spam\r\n",
        "easy_ham = read_file(\"easy_ham/\")\r\n",
        "hard_ham = read_file(\"hard_ham/\")\r\n",
        "spam = read_file(\"spam/\")\r\n",
        "\r\n",
        "\r\n",
        "#Make macro for CountVectorizer\r\n",
        "vectorizer = CountVectorizer()\r\n",
        "\r\n",
        "#data splitting\r\n",
        "hamtrain , hamtest = train_test_split(easy_ham + hard_ham , test_size = 0.3, random_state = 1) \r\n",
        "spamtrain , spamtest = train_test_split(spam , test_size = 0.3 , random_state = 1)\r\n",
        "easytrain , easytest = train_test_split(easy_ham , test_size = 0.3 , random_state = 1)\r\n",
        "hardtrain , hardtest = train_test_split(hard_ham , test_size = 0.3 , random_state = 1)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnbrbI0_OKCF"
      },
      "source": [
        "###2. Write a Python program that: \n",
        "1.\tUses four datasets (`hamtrain`, `spamtrain`, `hamtest`, and `spamtest`) \n",
        "2.\tTrains a Naïve Bayes classifier (e.g. Sklearn) on `hamtrain` and `spamtrain`, that classifies the test sets and reports True Positive and False Negative rates on the `hamtest` and `spamtest` datasets. You can use `CountVectorizer` to transform the email texts into vectors. Please note that there are different types of Naïve Bayes Classifier in SKlearn ([Documentation here](https://scikit-learn.org/stable/modules/naive_bayes.html)). Test two of these classifiers that are well suited for this problem\n",
        "    - Multinomial Naive Bayes  \n",
        "    - Bernoulli Naive Bayes. \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SFqy7Js3n8X"
      },
      "source": [
        "We made an algorithm for predicting if the emails were ham och spam. It would be optimal to create a function for this, but due to time constraints we didnt manage to do that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxuqjlrbOIu3"
      },
      "source": [
        "#Countvectorize hamtrain, hamtest , spamtrain, spamtest. Here we need the two combinations of trainig sets\r\n",
        "#given in the assignment. \r\n",
        "#In our case Xtrain is hamtrain and spamtrain, ytrain is the labels for the entire training set.\r\n",
        "#Compared to iris data sets\r\n",
        "hamspamtrainvector = vectorizer.fit_transform(hamtrain + spamtrain)\r\n",
        "easyspamtrainvector = vectorizer.fit_transform(easytrain + spamtrain)\r\n",
        "ham_test = vectorizer.transform(hamtest + spamtest)\r\n",
        "easy_test = vectorizer.transform(easytest + spamtest)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD3l6IBr4Ep9"
      },
      "source": [
        "We created labals for the data in order to create references for the predictions. $0$ indicates ham and $1$ indicates spam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MizO9DHn-0D_"
      },
      "source": [
        "#Create list with labels, ham is = 0 and spam is = 1\r\n",
        "hamspam_training_labels = ['0'] * len(hamtrain) + ['1'] * len(spamtrain)\r\n",
        "hamspam_test_labels = ['0'] * len(hamtest) + ['1'] * len(spamtest)\r\n",
        "\r\n",
        "#create list with labels for easyham set\r\n",
        "easyspam_training_labels = ['0'] * len(easytrain) + ['1'] * len(spamtrain)\r\n",
        "easyspam_test_labels = ['0'] * len(easytest) + ['1'] * len(spamtest)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJERHSCcGNaW"
      },
      "source": [
        "#MultinomialNB and BernoulliNB\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.naive_bayes import BernoulliNB\r\n",
        "\r\n",
        "#Now we want to train the naive bayes classifier on hamtrain and spamtrain\r\n",
        "\r\n",
        "#Creating macro for classifiers.\r\n",
        "multi_clf = MultinomialNB()\r\n",
        "bern_clf = BernoulliNB()\r\n",
        "\r\n",
        "#Train the model using the training sets, hamset\r\n",
        "multi_clf.fit(hamspamtrainvector,hamspam_training_labels)\r\n",
        "bern_clf.fit(hamspamtrainvector,hamspam_training_labels)\r\n",
        "\r\n",
        "#easy set\r\n",
        "multi_clf.fit(easyspamtrainvector , easyspam_training_labels)\r\n",
        "bern_clf.fit(easyspamtrainvector , easyspam_training_labels)\r\n",
        "\r\n",
        "#Predict the response for test dataset, ham\r\n",
        "multiham_pred = multi_clf.predict(ham_test)\r\n",
        "bernham_pred = bern_clf.predict(ham_test)\r\n",
        "\r\n",
        "#easy\r\n",
        "multieasy_pred = multi_clf.predict(easy_test)\r\n",
        "berneasy_pred = bern_clf.predict(easy_test)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zYTjEL7VSJD",
        "outputId": "86f0d653-d29f-4413-9967-a4b6a15c14ad"
      },
      "source": [
        "#Calculate accuracy for multinomial \r\n",
        "#Convert ham_test into a vector to match the labels.\r\n",
        "Xa = vectorizer.transform(hamtest + spamtest)\r\n",
        "Yb = hamspam_test_labels \r\n",
        "#Accuracy for ham_multinomial is :\r\n",
        "multiham_accu = multi_clf.score(Xa, Yb)\r\n",
        "\r\n",
        "#Accuracy for easy_multinomial is : \r\n",
        "Xb = vectorizer.transform(easytest + spamtest)\r\n",
        "Ya = easyspam_test_labels\r\n",
        "multieasy_accu = multi_clf.score(Xb,Ya)\r\n",
        "print('Multinomial prediction is : ' ,  'For ham :' ,multiham_accu, 'For easy : ' , multieasy_accu)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multinomial prediction is :  For ham : 0.9233870967741935 For easy :  0.9749182115594329\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3fNp49GR1tS",
        "outputId": "707d5972-e536-4e6c-ef01-96460d7d0748"
      },
      "source": [
        "#Calculate accuracy for bernoulli\r\n",
        "bernoham_accu = bern_clf.score(Xa, Yb)\r\n",
        "berneasy_accu = bern_clf.score(Xb,Ya)\r\n",
        "print('Bernoulli prediction is : ' ,  'For ham :' ,bernoham_accu, 'For easy : ' , berneasy_accu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bernoulli prediction is :  For ham : 0.8659274193548387 For easy :  0.916030534351145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRMQlf_3XU-M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30fac69f-9f5f-41a0-8129-631467b678c5"
      },
      "source": [
        "#Now lets calculate True positive, True negative for hamtest and spamtest\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "tp, fp, fn, tn = confusion_matrix(multiham_pred , hamspam_test_labels).ravel()\r\n",
        "print('For multinomial on the ham set we get :' ,'True positive is : ' , tp, 'True negative is : ' ,tn)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For multinomial on the ham set we get : True positive is :  786 True negative is :  130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c3HVsO5Ouo_",
        "outputId": "3a37ee5c-075e-476a-b2e2-bbee62ac896a"
      },
      "source": [
        "#Easy multinomial\r\n",
        "tp, fp, fn, tn = confusion_matrix(multieasy_pred , easyspam_test_labels).ravel()\r\n",
        "print('For multinomial on the easy set we get :' ,'True positive is : ' , tp, 'True negative is : ' ,tn)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For multinomial on the easy set we get : True positive is :  764 True negative is :  130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDUhjv9hPLAA",
        "outputId": "aa7b61fb-0cb3-4b63-9295-e4dab391e20e"
      },
      "source": [
        "#Ham bernoulli\r\n",
        "tp, fp, fn, tn = confusion_matrix(bernham_pred , hamspam_test_labels).ravel()\r\n",
        "print('For Bernoulli on the ham set we get :' ,'True positive is : ' , tp, 'True negative is : ' ,tn)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For Bernoulli on the ham set we get : True positive is :  785 True negative is :  74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9zljQKhH2T1",
        "outputId": "38b9622f-491d-4369-90ad-40f9152df85d"
      },
      "source": [
        "#Confusion matrix for bernoulli\r\n",
        "tp , fp , fn , tn = confusion_matrix(bernham_pred , hamspam_test_labels).ravel()\r\n",
        "print('For bernoulli on the hamset we get :' ,'True positive is : ' , tp, 'True negative is : ' ,tn)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For bernoulli on the hamset we get : True positive is :  785 True negative is :  74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oul631By2dBn"
      },
      "source": [
        "a) Explain how the classifiers differ. What different interpretations do they have? **1p** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI1bPDCvQxen"
      },
      "source": [
        "As the name suggests, the Multinomial Naïve Bayes classifier uses a counter for each discrete feature. In this case it counts each occurrence of a word in an email. \r\n",
        "\r\n",
        "Bernoulli Naïve Bayes on the other hand uses a binary/boolean response to discrete features. Meaning that it in our case only registers the binary occurrence of a feature and not how many times it occurs. The Bernoulli classifier also uses a rule that penalizes the non-occurrence of a, in this case, word.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDFS3uFFUcS7"
      },
      "source": [
        "### 3.Run your program on \n",
        "-\tSpam versus easy-ham \n",
        "-\tSpam versus (hard-ham + easy-ham). \n",
        "-   Discuss your results **2.5p** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gool_zb8Qzzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a840c5-0d0e-4f88-9a38-3e5a44617f91"
      },
      "source": [
        "#Now lets do spam versus easy - ham\r\n",
        "from random import seed\r\n",
        "from random import randint\r\n",
        "#Multinomial, on the hamset: \r\n",
        "#seed(1) if you want to repeat with same numbers as we had\r\n",
        "#pick a random mail from the test set\r\n",
        "#We made 1000 trials\r\n",
        "#These 2 are for multinomial\r\n",
        "\r\n",
        "trials_ham = []\r\n",
        "amount = 1000\r\n",
        "counter = 0\r\n",
        "for i in range(amount):\r\n",
        "  randnum = randint(0,len(hamspam_test_labels)-1)\r\n",
        "  prediction = multi_clf.predict(ham_test[randnum])\r\n",
        "  prediction = prediction[0].astype(int)\r\n",
        "  if(prediction == int(hamspam_test_labels[randnum])):\r\n",
        "    counter = counter + 1\r\n",
        "  trials_ham.append(prediction)\r\n",
        "summa_multi_ham = sum(trials_ham)\r\n",
        "ac_ham = counter / amount\r\n",
        "print('From 1000 (ham + spam) mails : ', summa_multi_ham , 'of them were spam.', 'Accuracy is : ', ac_ham )\r\n",
        "\r\n",
        "\r\n",
        "trials_easy = []\r\n",
        "amount = 1000\r\n",
        "counter_easy = 0\r\n",
        "for i in range(amount):\r\n",
        "  randnum = randint(0,len(easyspam_test_labels)-1)\r\n",
        "  prediction = multi_clf.predict(easy_test[randnum])\r\n",
        "  prediction = prediction[0].astype(int)\r\n",
        "  if(prediction == int(easyspam_test_labels[randnum])):\r\n",
        "    counter_easy = counter_easy + 1\r\n",
        "  trials_easy.append(prediction)\r\n",
        "summa_multi_easy = sum(trials_easy)\r\n",
        "ac_easy = counter_easy / amount\r\n",
        "print('From 1000 (easy + spam) mails : ', summa_multi_easy , 'of them were spam.', 'Accuracy is : ', ac_easy )\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From 1000 (ham + spam) mails :  215 of them were spam. Accuracy is :  0.917\n",
            "From 1000 (easy + spam) mails :  151 of them were spam. Accuracy is :  0.983\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aOLq5BOqtKD",
        "outputId": "46b7f9b5-7984-4d88-be24-884d1000803f"
      },
      "source": [
        "#These 2 are for bernoulli\r\n",
        "\r\n",
        "trials_ham = []\r\n",
        "amount = 1000\r\n",
        "counter = 0\r\n",
        "for i in range(amount):\r\n",
        "  randnum = randint(0,len(hamspam_test_labels)-1)\r\n",
        "  prediction = bern_clf.predict(ham_test[randnum])\r\n",
        "  prediction = prediction[0].astype(int)\r\n",
        "  if(prediction == int(hamspam_test_labels[randnum])):\r\n",
        "    counter = counter + 1\r\n",
        "  trials_ham.append(prediction)\r\n",
        "summa_berno_ham = sum(trials_ham)\r\n",
        "ac_ham = counter / amount\r\n",
        "print('From 1000 (ham + spam) mails : ', summa_multi_ham , 'of them were spam.', 'Accuracy is : ', ac_ham )\r\n",
        "\r\n",
        "\r\n",
        "trials_easy = []\r\n",
        "amount = 1000\r\n",
        "counter_easy = 0\r\n",
        "for i in range(amount):\r\n",
        "  randnum = randint(0,len(easyspam_test_labels)-1)\r\n",
        "  prediction = bern_clf.predict(easy_test[randnum])\r\n",
        "  prediction = prediction[0].astype(int)\r\n",
        "  if(prediction == int(easyspam_test_labels[randnum])):\r\n",
        "    counter_easy = counter_easy + 1\r\n",
        "  trials_easy.append(prediction)\r\n",
        "summa_berno_easy = sum(trials_easy)\r\n",
        "ac_easy = counter_easy / amount\r\n",
        "print('From 1000 (easy + spam) mails : ', summa_berno_easy , 'of them were spam.', 'Accuracy is : ', ac_easy )\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From 1000 (ham + spam) mails :  215 of them were spam. Accuracy is :  0.871\n",
            "From 1000 (easy + spam) mails :  74 of them were spam. Accuracy is :  0.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzLu1TOAfor7"
      },
      "source": [
        "As we can see both models did fairly well. They both performed better on the 'easy' spam as would be expected. The fact that our Multinomial model does a better job could be due to it tracking occurences of words and therefore getting a more accurate result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkfQWBB4UhYd"
      },
      "source": [
        "# 4.\tTo avoid classification based on common and uninformative words it is common to filter these out. \n",
        "\n",
        "**a.** Argue why this may be useful. Try finding the words that are too common/uncommon in the dataset. **1p** \n",
        "\n",
        "**b.** Use the parameters in Sklearn’s `CountVectorizer` to filter out these words. Update the program from point 3 and run it on your data and report and discuss your results. You have two options to do this in Sklearn: either using the words found in part (a) or letting Sklearn do it for you. Argue for your decision-making. **1p** \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PS6pZExLo4v"
      },
      "source": [
        "Too uncommon words might lead to misclassifications. A word that only occurs a couple of time or times and only in one category might lead that being misrepresented as spam or ham. Using very common words on the other hand might lead the model to use these words that are not indicative of spam or ham to determine the class of the message."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eX0CRDw5K1P",
        "outputId": "4f395497-24a8-4ebe-c5a5-0e8d18d609db"
      },
      "source": [
        "# Inspiration for code from 'https://medium.com/@cristhianboujon/how-to-list-the-most-common-words-from-text-corpus-using-scikit-learn-dad4d0cab41d'\r\n",
        "def top_n_common_words(data, n=None):\r\n",
        "\tvct = CountVectorizer().fit(data)\r\n",
        "\twords_matrix = vct.transform(data)\r\n",
        "\twords_vector = words_matrix.sum(axis=0)\r\n",
        "\twords_occur = [(word, words_vector[0, idx]) for word, idx in vct.vocabulary_.items()]\r\n",
        "\twords_occur = sorted(words_occur, key = lambda x: x[1], reverse=True)\r\n",
        "\treturn words_occur[:n]\r\n",
        "\r\n",
        "print('The top 20 most common words are:')\r\n",
        "top_n_common_words(hamtrain + spamtrain, 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The top 20 most common words are:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('com', 46562),\n",
              " ('the', 29048),\n",
              " ('to', 27021),\n",
              " ('http', 21026),\n",
              " ('from', 20157),\n",
              " ('2002', 19904),\n",
              " ('3d', 19314),\n",
              " ('td', 18480),\n",
              " ('for', 16722),\n",
              " ('net', 15788),\n",
              " ('with', 15601),\n",
              " ('font', 15218),\n",
              " ('by', 15131),\n",
              " ('of', 14602),\n",
              " ('and', 14553),\n",
              " ('width', 13699),\n",
              " ('localhost', 13264),\n",
              " ('id', 12731),\n",
              " ('received', 12507),\n",
              " ('example', 11534)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rkqo_aStlh1",
        "outputId": "1ea5445e-4a90-4bc4-f606-41dfe2afe611"
      },
      "source": [
        "def top_n_common_words(data, n=None):\r\n",
        "\tvct = CountVectorizer().fit(data)\r\n",
        "\twords_matrix = vct.transform(data)\r\n",
        "\twords_vector = words_matrix.sum(axis=0)\r\n",
        "\twords_occur = [(word, words_vector[0, idx]) for word, idx in vct.vocabulary_.items()]\r\n",
        "\twords_occur = sorted(words_occur, key = lambda x: x[1], reverse=True)\r\n",
        "\treturn words_occur[-n:]\r\n",
        "\r\n",
        "print('The top 20 least common words are:')\r\n",
        "top_n_common_words(hamtrain + spamtrain, 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The top 20 least common words are:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('e6_d_ladydoc', 1),\n",
              " ('e6_d_samtote_06', 1),\n",
              " ('e6_d_samtote_14', 1),\n",
              " ('samsonite', 1),\n",
              " ('tote', 1),\n",
              " ('e6_d_totes135', 1),\n",
              " ('e6_d_samtote_24', 1),\n",
              " ('e6_d_samtote_', 1),\n",
              " ('f8f0ff', 1),\n",
              " ('abide', 1),\n",
              " ('9739916f03', 1),\n",
              " ('g8p8uzc19035', 1),\n",
              " ('jaa23850', 1),\n",
              " ('yu2now910', 1),\n",
              " ('200209250706', 1),\n",
              " ('l23405678', 1),\n",
              " ('tingle', 1),\n",
              " ('crains', 1),\n",
              " ('list6644', 1),\n",
              " ('postino', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcyVfOZFU4F_"
      },
      "source": [
        "### 5. Eeking out further performance\n",
        "**a.**  Use a lemmatizer to normalize the text (for example from the `nltk` library). For one implementation look at the documentation ([here](https://scikit-learn.org/stable/modules/feature_extraction.html#customizing-the-vectorizer-classes)). Run your program again and answer the following questions: \n",
        "  - Why can lemmatization help?\n",
        "  -\tDoes the result improve from 3 and 4? Discuss. **1.5p** \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqAATeE4PCip"
      },
      "source": [
        "Lemmetization helps group words with different inflected forms. This in theory helps with analyzing data, as words with the same meaning can be analyzed as one item. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBkI74s62dBo"
      },
      "source": [
        "#code\r\n",
        "#using a lemmatizer to normalize the text\r\n",
        "#Should improve complexity as the pool gets smaller.\r\n",
        "#import nltk \r\n",
        "#from nltk.stem.wordnet import WordNetLemmatizer\r\n",
        "#wnl = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByOQSUfL0BG8"
      },
      "source": [
        "We were not able to solve the code parts of question 5, this is what we could come up with. In order to complete this part we needed to make the vectorizations to lowercase but unfortunatly we didnt manage this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-UiwVMQLCpG"
      },
      "source": [
        "from nltk.stem.wordnet import WordNetLemmatizer\r\n",
        "from nltk import word_tokenize\r\n",
        "easy_mails = easy_ham\r\n",
        "lmtzr = WordNetLemmatizer()\r\n",
        "\r\n",
        "#Define function for lemmatizing files\r\n",
        "def lemmatizer_fun(file):\r\n",
        "  lemmatized = [[lmtzr.lemmatize(word) for word in word_tokenize(s)]\r\n",
        "              for s in easy_mails]\r\n",
        "  #[x.lower() for x in lemmatized]\r\n",
        "  return lemmatized\r\n",
        "  \r\n",
        "#lemmatize all the data\r\n",
        "#easy_ham_lemmatized = lemmatizer_fun(easy_ham)\r\n",
        "#hard_ham_lemmatized = lemmatizer_fun(hard_ham)\r\n",
        "#spam_lemmatized = lemmatizer_fun(spam)\r\n",
        "\r\n",
        "#lemmatize the split data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwh9E--aLwRH"
      },
      "source": [
        "easy_ham = lemmatizer_fun(easy_ham)\r\n",
        "hard_ham = lemmatizer_fun(hard_ham)\r\n",
        "spam = lemmatizer_fun(spam)\r\n",
        "\r\n",
        "\r\n",
        "#data splitting\r\n",
        "#Here is where the algorithm stops working.\r\n",
        "hamtrain , hamtest = train_test_split(easy_ham + hard_ham , test_size = 0.3, random_state = 1) \r\n",
        "spamtrain , spamtest = train_test_split(spam , test_size = 0.3 , random_state = 1)\r\n",
        "easytrain , easytest = train_test_split(easy_ham , test_size = 0.3 , random_state = 1)\r\n",
        "hardtrain , hardtest = train_test_split(hard_ham , test_size = 0.3 , random_state = 1)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JtUY4TgQ7Is"
      },
      "source": [
        "#Vectorize\r\n",
        "hamspamtrainvector = vectorizer.fit_transform(hamtrain + spamtrain)\r\n",
        "easyspamtrainvector = vectorizer.fit_transform(easytrain + spamtrain)\r\n",
        "ham_test = vectorizer.transform(hamtest + spamtest)\r\n",
        "easy_test = vectorizer.transform(easytest + spamtest)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz1PhBgkSYXO"
      },
      "source": [
        "#Train the model using the training sets, hamset\r\n",
        "\r\n",
        "multi_clf.fit(hamspamtrainvector,hamspam_training_labels)\r\n",
        "bern_clf.fit(hamspamtrainvector,hamspam_training_labels)\r\n",
        "\r\n",
        "#easy set\r\n",
        "multi_clf.fit(easyspamtrainvector , easyspam_training_labels)\r\n",
        "bern_clf.fit(easyspamtrainvector , easyspam_training_labels)\r\n",
        "\r\n",
        "#Predict the response for test dataset, ham\r\n",
        "multiham_pred = multi_clf.predict(ham_test)\r\n",
        "bernham_pred = bern_clf.predict(ham_test)\r\n",
        "\r\n",
        "#easy\r\n",
        "multieasy_pred = multi_clf.predict(easy_test)\r\n",
        "berneasy_pred = bern_clf.predict(easy_test)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qd2BAz02USAy"
      },
      "source": [
        "\r\n",
        "trials_ham = []\r\n",
        "amount = 1000\r\n",
        "counter = 0\r\n",
        "for i in range(amount):\r\n",
        "  randnum = randint(0,len(hamspam_test_labels)-1)\r\n",
        "  prediction = multi_clf.predict(ham_test[randnum])\r\n",
        "  prediction = prediction[0].astype(int)\r\n",
        "  if(prediction == int(hamspam_test_labels[randnum])):\r\n",
        "    counter = counter + 1\r\n",
        "  trials_ham.append(prediction)\r\n",
        "summa_multi_ham = sum(trials_ham)\r\n",
        "ac_ham = counter / amount\r\n",
        "#print('From 1000 (ham + spam) mails : ', summa_multi , 'of them were spam.', 'Accuracy is : ', ac )\r\n",
        "\r\n",
        "\r\n",
        "trials_easy = []\r\n",
        "amount = 1000\r\n",
        "counter_easy = 0\r\n",
        "for i in range(amount):\r\n",
        "  randnum = randint(0,len(easyspam_test_labels)-1)\r\n",
        "  prediction = multi_clf.predict(easy_test[randnum])\r\n",
        "  prediction = prediction[0].astype(int)\r\n",
        "  if(prediction == int(easyspam_test_labels[randnum])):\r\n",
        "    counter_easy = counter_easy + 1\r\n",
        "  trials_easy.append(prediction)\r\n",
        "summa_multi_easy = sum(trials_easy)\r\n",
        "ac_easy = counter_easy / amount\r\n",
        "print('From 1000 (easy + spam) mails : ', summa_multi_ham , 'of them were spam.', 'Accuracy is : ', ac_easy )\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9cHcuc32dBp"
      },
      "source": [
        "**b.** The split of the data set into a training set and a test set can lead to very skewed results. Why is this, and do you have suggestions on remedies? \n",
        " What do you expect would happen if your training set were mostly spam messages while your test set were mostly ham messages?  **1p** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_zCck8q2dBp"
      },
      "source": [
        "Skewed results can emerge if the test and training set do not represent the data well enough. If the training set is comprised of mostly data for one label, it can lead to a bias towards the majority labels. To mitigate skewed results, you can use sampling and weighting when calibrating the train/test data. \r\n",
        "\r\n",
        "A more concrete way is to use the built-in function “stratify” in sklearn’s train_test_split method. This causes the data used for training/testing to contain approximately the same percentages of the labels as the complete data set.\r\n",
        "\r\n",
        "If the training set was mostly spam and the test set mostly consisted of ham messages it would probably result in a lot of false negative classifications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_nyGug9U4f3"
      },
      "source": [
        "**c.** Re-estimate your classifier using `fit_prior` parameter set to `false`, and answer the following questions:\n",
        "  - What does this parameter mean?\n",
        "  - How does this alter the predictions? Discuss why or why not. **0.5p** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4J9TXMxTTWI"
      },
      "source": [
        "The sklearn documentation states that if fit_prior is set to false; \"a uniform prior will be used.\". This means that priors will not be adjusted based on the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr0JE9mC2dBp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax6_OgKb2dBp"
      },
      "source": [
        "**d.** The python model includes smoothing (`alpha` parameter ), explain why this can be important. \n",
        "  - What would happen if in the training data set the word 'money' only appears in spam examples? What would the model predict about a message containing the word 'money'? Does the prediction depend on the rest of the message and is that reasonable? Explain your reasoning  **1p** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0joKX81YNs5"
      },
      "source": [
        "If the word 'money' only occurs in spam examples smoothing becomes very helpful. Without smoothing the model would interpret this as meaning 'money' only will occur in spam messages. The word 'money' can ofcourse be appear in ham messages, so predicting solely based on this becomes very unreasonable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mL3yynv2dBp"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND6FKoexVAhW"
      },
      "source": [
        "### What to report and how to hand in.\n",
        "\n",
        "- You will need to clearly report all results in the notebook in a clear and appropriate way, either using plots or code output (f.x. \"print statements\"). \n",
        "- The notebook must be reproducible, that means, we must be able to use the `Run all` function from the `Runtime` menu and reproduce all your results. **Please check this before handing in.** \n",
        "- Save the notebook and share a link to the notebook (Press share in upper left corner, and use `Get link` option. **Please make sure to allow all with the link to open and edit.**\n",
        "- Edits made after submission deadline will be ignored, graders will recover the last saved version before deadline from the revisions history.\n",
        "- **Please make sure all cells are executed and all the output is clearly readable/visible to anybody opening the notebook.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bI3z_spVacz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}